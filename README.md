# Image-Captioning-with-Transfer-Learning-and-Transformer-Decoder
This project implements an advanced image captioning model using a hybrid architecture: an EfficientNetV2 backbone for image feature extraction, followed by a Transformer Encoder-Decoder for sequence generation. The model is trained and evaluated on the Flickr8k dataset, with capabilities for scaling to Flickr30k.
